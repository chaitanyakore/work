#!/usr/bin/python

# =====================================================================================================================
#
#          FILE: cs-backup
#
#   DESCRIPTION: Contentserv CS backup script
#
#          BUGS: https://contentserv.atlassian.net/issues
#
#     COPYRIGHT: (c) 2017 by Contentserv GmbH
#
#        AUTHOR: Chaitanya Kore
#       LICENSE: Proprietary
#  ORGANIZATION: Contentserv GmbH (contentserv.com)
#       CREATED: 16.10.2017 15:30 CET
# =====================================================================================================================

# Attempt to make this script version-independent
# and allow running in both 2.7 and 3.x
from __future__ import print_function

import argparse
import os
import errno
import re
import fnmatch
import sys
import subprocess
import requests
import json
import pymysql

from datetime import datetime
from cassandra.cluster import Cluster
from pyjavaproperties import Properties

# Set some CS-related globals
# "stop-dirs". They reside under webroot and should never contain project data
cs_reserved_dirs = ['admin', 'admin.local', 'admin.doc', 'admin.test', 'data', 'bin']

# Call mode
cs_restore_mode = False

# Some important regexes. Note the 'r' prefix (enforced ASCII), current python
# native implementation of regex ('re' library) does not work well with unicode
# patterns (however searching in unicode strings works fine)
cs_project_config_regex = r'^\/[a-zA-Z0-9_]+\/data\/config.php'
cs_project_name_extraction_regex = r'^\/([a-zA-Z0-9_]+)\/data\/config.php'
cs_project_properties_regex = r'^\/data\/exportstaging\/config\/properties\/.*'

cs_elastic_snapshot_name = r'cs_snapshot'
cs_elastic_snapshot_repo = r'cs_backup'
cs_ee_startstop_script = r'admin/core/extensions/exportstaging/java/dist/ExportExecutorNG.sh'

# Determine if the console support colors
color_terminal = False
try:
    tput_colors = int(subprocess.check_output("tput colors", shell=True))
    if tput_colors > 2:
        color_terminal = True
except:
    color_terminal = False


class tcolors:
    RED = '\033[31m' if color_terminal else ''
    GREEN = '\033[32m' if color_terminal else ''
    BLUE = '\033[34m' if color_terminal else ''
    YELLOW = '\033[33m' if color_terminal else ''
    BOLDRED = '\033[1;31m' if color_terminal else ''
    BOLDGREEN = '\033[1;32m' if color_terminal else ''
    BOLDBLUE = '\033[1;34m' if color_terminal else ''
    BOLDYELLOW = '\033[1;33m' if color_terminal else ''
    CANCEL = '\033[0m' if color_terminal else ''


# Turn debug OFF by default
cs_enable_debug = False

# Check global debug env variable
try:
    env_enable_debug = os.environ["CS_ENABLE_DEBUG"].lower()
    print(env_enable_debug)
    if env_enable_debug in ['true', 'yes', '1', 'y']:
        cs_enable_debug = True
    else:
        cs_enable_debug = False
except:
    cs_enable_debug = False


def printdeb(*args, **kwargs):
    """Universal debug printing function"""
    if cs_enable_debug:
        print(tcolors.BOLDBLUE + ' * DEBUG: ' + tcolors.CANCEL, end="")
        print(*args, **kwargs)


def printerr(*args, **kwargs):
    """Universal error printing function"""
    print(tcolors.BOLDRED, file=sys.stderr, end="")
    print(*args, file=sys.stderr, **kwargs)
    print(tcolors.CANCEL, file=sys.stderr, end="")


def printinf(*args, **kwargs):
    """Universal infomessage printing function"""
    print(tcolors.BOLDGREEN + ' *  INFO: ' + tcolors.CANCEL, end="")
    print(*args, **kwargs)


def CreateNowDir(root):
    newdir = os.path.join(root,
        datetime.now().strftime('%Y-%m-%d_%H:%M:%S'))
    try:
        os.makedirs(newdir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise  # This was not a "directory exist" error..
    return newdir

def ApacheStop():
    call_str = 'sudo systemctl stop apache2.service'
    retval = subprocess.call(call_str, shell=True)
    if retval != 0:
        printerr("Unable to stop Apache")
        return 1
    else:
        printdeb("Apache successfully stopped")

def ApacheStart():
    call_str = 'sudo systemctl start apache2.service'
    retval = subprocess.call(call_str, shell=True)
    if retval != 0:
        printerr("Unable to start Apache")
        return 1
    else:
        printdeb("Apache successfully started")


def CreateLatestLink(target):
    short_dirname = os.path.basename(os.path.normpath(target))
    path_to_dir = os.path.dirname(os.path.normpath(target))
    printdeb("Creating \'latest\' symlink to the dir:", short_dirname, "in", path_to_dir)
    link_full_name = os.path.join(path_to_dir, 'latest')
    # delete the symlink if already exists
    # operation will also fail if 'latest' exists
    # and it's NOT a symlink
    if os.path.islink(link_full_name):
        try:
            os.unlink(link_full_name)
        except:
            printerr("Failed to remove symlink \'latest\'")
            raise SystemExit(1)
    try:
        os.symlink(short_dirname, link_full_name)
    except:
        raise


class ContentservProject:
    """A Contentserv-CS project (each CS instance can hold multiple projects)"""
    def __init__(self, project_config_relpath, webroot):

        self.cassandra_ok = False
        self.cassandra_keyspaces = []
        self.cassandra_host = ''
        self.cassandra_port = ''
        self.cassandra_project_keyspace = ''

        self.elastic_ok = False
        self.elastic_host = ''
        self.elastic_http_port = ''
        self.elastic_cluster = ''
        self.elastic_index = ''

        self.mysql_ok = False
        self.mysql_host = ''
        self.mysql_port = ''
        self.mysql_username = ''
        self.mysql_password = ''
        self.mysql_database = ''

        self.pname = re.sub(cs_project_name_extraction_regex, r'\1', project_config_relpath)
        self.ppath = os.path.join(webroot, self.pname)
        # as of today, only one directory per project should be backed up
        # but we create a list of directories anyway, to be future-proof
        self.pdirs = ['data/exportstaging/config/ExportData/json']

        printdeb("Initializing project with full path:", self.ppath)

        # Collect project's *.properties files
        filenames_and_wildcards = ['*.properties']
        filematches = []
        for root, dirnames, filenames in os.walk(self.ppath):
            for extensions in filenames_and_wildcards:
                for filename in fnmatch.filter(filenames, extensions):
                    filematches.append(os.path.join(root, filename))
        filematches_relative = [x[len(self.ppath):] for x in filematches]
        self.pproperties = []
        self.pproperties = [x for x in filematches_relative if re.search(cs_project_properties_regex, x)]
        printdeb(self.pproperties.__len__(), "properties file found")

        # Finding Cassandra config
        cassandra_properties = [x for x in self.pproperties if "cassandra.properties" in x]
        if cassandra_properties.__len__() == 1:
            self.cassandra_properties = self.ppath + ''.join(cassandra_properties)
        else:
            self.cassandra_properties = ''

        printdeb("Cassandra config:", self.cassandra_properties)
        self.ActivateCassandra()

        # Finding ElasticSearch config
        elastic_properties = [x for x in self.pproperties if "elasticsearch.properties" in x]
        if elastic_properties.__len__() == 1:
            self.elastic_properties = self.ppath + ''.join(elastic_properties)
        else:
            self.elastic_properties = ''

        printdeb("ElasticSearch config:", self.elastic_properties)
        self.ActivateElastic()

        # Finding MySQL config
        mysql_properties = [x for x in self.pproperties if "mysql.properties" in x]
        if mysql_properties.__len__() == 1:
            self.mysql_properties = self.ppath + ''.join(mysql_properties)
        else:
            self.mysql_properties = ''

        printdeb("MySQL config:", self.mysql_properties)
        self.ActivateMySQL()

    def ActivateCassandra(self):
        if self.cassandra_properties != '':
            props = Properties()
            try:
                props.load(open(self.cassandra_properties))
            except:
                self.cassandra_ok = False
                return
        else:
            self.cassandra_ok = False
            return

        printdeb("Cassandra host:", props['cassandra.connection.url'])
        printdeb("Cassandra port:", props['cassandra.connection.port'])
        printdeb("Cassandra keyspace:", props['cassandra.keyspace'])

        self.cassandra_host = props['cassandra.connection.url']
        self.cassandra_port = props['cassandra.connection.port']
        self.cassandra_project_keyspace = props['cassandra.keyspace']

        # We collect project keyspace name for reference only, due to design failure in
        # the current CS release, we have to backup all non-system keyspaces anyway

        cass_cluster = Cluster([self.cassandra_host], port=self.cassandra_port)
        cass_session = cass_cluster.connect()
        cass_all_keyspaces = cass_cluster.metadata.keyspaces
        self.cassandra_keyspaces = [y.name for x, y in cass_all_keyspaces.iteritems() if not x.startswith(u'system')]

        if self.cassandra_keyspaces.__len__() > 0:
            self.cassandra_ok = True
            printdeb("Cassandra OK")
        else:
            self.cassandra_ok = False
            printdeb("Failed to gather list of non-system keyspaces from Cassandra")

        printdeb("Cassandra session open: ", cass_session.hosts)
        printdeb("Cassandra keyspaces: ", self.cassandra_keyspaces)


    def ActivateElastic(self):
        if self.elastic_properties != '':
            props = Properties()
            try:
                props.load(open(self.elastic_properties))
            except:
                self.elastic_ok = False
                return
        else:
            self.elastic_ok = False
            return

        self.elastic_host = props['elasticsearch.address']
        self.elastic_http_port = props['elasticsearch.http.port']
        self.elastic_cluster = props['elasticsearch.cluster']
        self.elastic_index = props['elasticsearch.index.prefix']

        printdeb("ElasticSearch host:", self.elastic_host)
        printdeb("ElasticSearch HTTP port:", self.elastic_http_port)
        printdeb("ElasticSearch cluster name:", self.elastic_cluster)
        printdeb("ElasticSearch index:", self.elastic_index)

        elastic_url_prefix = 'http://' + self.elastic_host + ':' + self.elastic_http_port + '/'
        response = requests.get(elastic_url_prefix + '_nodes?pretty')
        if not response.ok:
            self.elastic_ok = False
            return

        # printdeb("Elastic _nodes request response:", response.text)

        elastic_nodes_response = response.json()
        printdeb("Elastic Cluster name:", elastic_nodes_response['cluster_name'])
        printdeb("Elastic Cluster number of nodes:", elastic_nodes_response['nodes'].__len__())
        if elastic_nodes_response['nodes'].__len__() < 1:
            self.elastic_ok = False
            return

        # We work only with the first node in the returned list
        printdeb("Elastic Node UID:", elastic_nodes_response['nodes'].keys()[0])
        printdeb("Elastic Node name:", elastic_nodes_response['nodes'].values()[0]['name'])

        # Probing backup repo path var
        try:
            self.elastic_repo_path = elastic_nodes_response['nodes'].values()[0]['settings']['path']['repo']
            printdeb("Elastic Node repo path:", self.elastic_repo_path)
        except:
            printdeb("Elastic Cluster node has no backup repo path set, backup/snapshots won't work")
            self.elastic_ok = False
            return

        payload = {"type": "fs", "settings": {"location": self.elastic_repo_path}}
        response = requests.put(elastic_url_prefix + '_snapshot/' + cs_elastic_snapshot_repo +
                                '?pretty', data=json.dumps(payload))
        printdeb("Elastic repo creation response:", response.text)
        if not response.ok:
            self.elastic_ok = False
            return

    def ActivateMySQL(self):
        if self.mysql_properties != '':
            props = Properties()
            try:
                props.load(open(self.mysql_properties))
            except:
                printerr("Unable to find MySQL configuration, aborting...")
                raise SystemExit(1)
        else:
            printerr("Unable to find MySQL configuration, aborting...")
            raise SystemExit(1)

        self.mysql_host = props['jdbc.address']
        self.mysql_port = props['jdbc.port']
        self.mysql_username = props['jdbc.username']
        self.mysql_password = props['jdbc.password']
        self.mysql_database = props['export.intermediate.database']

        try:
            conn = pymysql.connect(host=self.mysql_host,
                                   user=self.mysql_username,
                                   password=self.mysql_password,
                                   db=self.mysql_database)
            if conn.open:
                printdeb("Connected to MySQL database")
                self.mysql_ok = True
                conn.close()
            else:
                printerr("Unable to connect to MySQL, aborting...")
                raise SystemExit(1)
        except:
            printerr("Unable to connect to MySQL, aborting...")
            raise SystemExit(1)

    def DumpMySQL(self, path_to_container):
        printdeb("Dump the MySQL database")
        dumpname = os.path.join(path_to_container, self.pname + '_mysqldump.xz')
        if not self.mysql_ok:
            printerr("MySQL is not available or not configured, aborting")
            raise SystemExit(1)
        mysqldump_call = 'mysqldump -x --host=' + self.mysql_host + ' --port=' + self.mysql_port + \
                         ' --user=' + self.mysql_username + ' --password=' + self.mysql_password + ' ' + \
                         self.mysql_database + ' | xz >' + dumpname
        printdeb("MySQL dump will be called:", mysqldump_call)
        mysql_retval = subprocess.call(mysqldump_call, shell=True)
        if mysql_retval != 0:
            printerr("mysqldump failed, aborting...")
            raise SystemExit(mysql_retval)
        printdeb("MySQL dump successfully finished")

    def RestoreMySQL(self, path_to_container):
        printdeb("Restoring the MySQL database")
        dumpname = os.path.join(path_to_container, self.pname + '_mysqldump.xz')
        if not self.mysql_ok:
            printerr("MySQL is not available or not configured, aborting")
            raise SystemExit(1)
        mysqlrestore_call = 'xzcat ' + dumpname + ' |mysql --host=' + self.mysql_host + \
                            ' --port=' + self.mysql_port + ' --user=' + self.mysql_username + \
                            ' --password=' + self.mysql_password + ' ' + self.mysql_database
        printdeb("MySQL will be called:", mysqlrestore_call)
        mysql_retval = subprocess.call(mysqlrestore_call, shell=True)
        if mysql_retval != 0:
            printerr("mysql command failed, aborting...")
            raise SystemExit(mysql_retval)
        printdeb("MySQL restore successfully finished")

    def ElasticSnapshotCleanup(self):
        """Cleanup ElasticSearch snapshot repo"""
        elastic_url_prefix = 'http://' + self.elastic_host + ':' + self.elastic_http_port + '/'
        response = requests.get(elastic_url_prefix + '_snapshot/' + cs_elastic_snapshot_repo + '/_all')
        if not response.ok:
            self.elastic_ok = False
            return
        elastic_response = response.json()
        snapshots_list = elastic_response['snapshots']
        printdeb("Snapshots found:", snapshots_list.__len__())
        if snapshots_list.__len__() > 0:
            for x in snapshots_list:
                sname = x['snapshot']
                printdeb('Snapshot to delete:', sname)
                response = requests.delete(elastic_url_prefix + '_snapshot/' + cs_elastic_snapshot_repo
                                           + '/' + sname + '?wait_for_completion')
                elastic_response = response.json()
                if (not response.ok) or (not elastic_response['acknowledged']):
                    printerr("Unable to delete ElasticSearch snapshot:", sname)
                    return
                printdeb("Snapshot", sname, "removed")

    def SnapshotElastic(self, path_to_container):
        """Backup ElasticSearch using its snapshot functionality"""
        printdeb("Create ElasticSearch Snapshot")
        # Currently no incremental snapshots supported, so the
        # snapshot with hardcoded name 'cs_snapshot' will be used
        self.ElasticSnapshotCleanup()
        # OK, clean, all set, ready to create a fresh one
        elastic_url_prefix = 'http://' + self.elastic_host + ':' + self.elastic_http_port + '/'
        response = requests.put(elastic_url_prefix + '_snapshot/' + cs_elastic_snapshot_repo
                                           + '/' + cs_elastic_snapshot_name + '?wait_for_completion')
        elastic_response = response.json()
        if (not response.ok) or (not elastic_response['snapshot']['state'] == 'SUCCESS'):
            printerr("Unable to create ElasticSearch snapshot:", cs_elastic_snapshot_name)
            return
        printdeb("Snapshot", cs_elastic_snapshot_name, "successfully created on the ElasticSearch Cluster")
        snapshot_name = os.path.join(path_to_container, self.pname + '_elastic_snapshot.tar.xz')
        tar_call = 'tar cJf ' + snapshot_name + ' -C ' + self.elastic_repo_path + ' .'
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("cannot compress ElasticSearch snapshot, skipping...")
            if os.path.exists(snapshot_name):
                printdeb("Deleting the empty archive")
                os.unlink(snapshot_name)
            return
        printdeb("Elastic snapshot archived successfully")

    def RestoreElastic(self, path_to_container):
        """Restore ElasticSearch from snapshot archive"""
        printdeb("Restoring ElasticSearch from snapshot")
        # Currently no incremental snapshots supported, so the
        # snapshot with hardcoded name 'cs_snapshot' will be used
        self.ElasticSnapshotCleanup()
        # OK, clean, all set, ready to restore
        elastic_url_prefix = 'http://' + self.elastic_host + ':' + self.elastic_http_port + '/'
        snapshot_name = os.path.join(path_to_container, self.pname + '_elastic_snapshot.tar.xz')
        tar_call = 'sudo tar xJ --overwrite-dir -f ' + snapshot_name + ' -C ' + self.elastic_repo_path
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("cannot uncompress ElasticSearch snapshot, skipping...")
            return
        # first, close all indices
        response = requests.post(elastic_url_prefix + '*/_close?wait_for_completion')
        elastic_response = response.json()
        if (not response.ok) or (not elastic_response['acknowledged'] == True):
            printerr("Unable to close ElasticSearch indices, cannot proceed to restore...")
            return
        response = requests.post(elastic_url_prefix + '_snapshot/' + cs_elastic_snapshot_repo
                                + '/' + cs_elastic_snapshot_name + '/_restore?wait_for_completion')
        elastic_response = response.json()
        if (not response.ok) or (not elastic_response['snapshot']['shards']['total'] ==
                                     elastic_response['snapshot']['shards']['successful']):
            printerr("Unable to restore ElasticSearch snapshot:", cs_elastic_snapshot_name)
            return
        printinf("Successfully restored ElasticSearch snapshot:", cs_elastic_snapshot_name)
        # re-open all indices, ignore the response, cause part of them could already be opened
        # which would produce error(s)
        response = requests.post(elastic_url_prefix + '*/_open?wait_for_completion')

    def DumpCassandra(self, path_to_container):
        """Cassandra will be dumped using external tool (python script)"""
        if not self.cassandra_ok:
            printinf("Cassandra is either not ready or not configured for project:", self.pname)
            return
        printdeb("Dumping Cassandra for project:", self.pname)
        dump_name = os.path.join(path_to_container, self.pname + '_cassandra_dump.cql')
        keyspaces_to_dump = ''
        for ks in self.cassandra_keyspaces:
            keyspaces_to_dump = keyspaces_to_dump + ' --keyspace ' + ks

        cassdump_call = 'cs-cassandradump.py --host ' + self.cassandra_host + \
                        ' --port ' + self.cassandra_port + ' --export-file ' \
                        + dump_name + keyspaces_to_dump
        printdeb("Dump tool will be called:", cassdump_call)
        cassdump_retval = subprocess.call(cassdump_call, shell=True)
        if cassdump_retval != 0:
            printerr("cannot dump Cassandra, skipping...")
            return
        printdeb("CQL dump created successfully, proceed to xzipping")
        xz_call = 'xz ' + dump_name
        xz_retval = subprocess.call(xz_call, shell=True)
        if xz_retval != 0:
            printerr("Cannot xzip CQL dump file, skipping")
            return
        printdeb("Cassandra dump successfully created:", dump_name + '.xz')

    def RestoreCassandra(self, path_to_container):
        """Restore Cassandra from archived *.xz file"""
        if not self.cassandra_ok:
            printinf("Cassandra is either not ready or not configured for project:", self.pname)
            return
        printdeb("Restoring Cassandra for project:", self.pname)
        dump_xz_name = os.path.join(path_to_container, self.pname + '_cassandra_dump.cql.xz')
        xz_call = 'xz -d -k ' + dump_xz_name
        xz_retval = subprocess.call(xz_call, shell=True)
        if xz_retval != 0:
            printerr("Cannot extract CQL dump from xz-archive")
            return
        dump_name = os.path.join(path_to_container, self.pname + '_cassandra_dump.cql')
        cassrestore_call = 'cs-cassandradump.py --host ' + self.cassandra_host + \
                        ' --port ' + self.cassandra_port + ' --import-file ' \
                        + dump_name
        cassrestore_retval = subprocess.call(cassrestore_call, shell=True)
        if cassrestore_retval != 0:
            printerr("Cannot restore Cassandra from CQL dump file")
            return
        # Delete temporary plain CQL dump file
        os.unlink(dump_name)
        printinf("Cassandra keyspaces successfully restored")

    def TarDirsAndFiles(self, path_to_container):
        """Add all project-related dirs and files to the backup container"""
        files_dump = os.path.join(path_to_container, self.pname + '_files.tar.xz')
        dirs_list = ''
        for dname in self.pdirs:
            dirs_list = dirs_list + ' ' + dname
        tar_call = 'tar cJf ' + files_dump + ' -C ' + self.ppath + ' ' + dirs_list
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("cannot backup project-related files...")
            if os.path.exists(files_dump):
                printdeb("Deleting the empty archive")
                os.unlink(files_dump)
            return
        printdeb("Project-related files and dirs archived successfully")

    def RestoreDirsAndFiles(self, path_to_container):
        """Reestore all project-related dist and files from *.tar.xz file"""
        files_dump = os.path.join(path_to_container, self.pname + '_files.tar.xz')
        tar_call = "sudo tar xJf " + files_dump + ' -C ' + self.ppath
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("cannot restore project-related files from *.tar.xz...")
            return
        printinf("Project-related files and dirs restored successfully")

    def DoBackup(self, path_to_container):
        """Backup the project to specified container directory"""
        printinf("Backing up the project:", self.pname)
        self.DumpMySQL(path_to_container)
        self.SnapshotElastic(path_to_container)
        self.DumpCassandra(path_to_container)
        self.TarDirsAndFiles(path_to_container)

    def DoRestore(self, path_to_container):
        """Restore the project from the specified directory"""
        printinf("Restoring the project:", self.pname)
        self.RestoreMySQL(path_to_container)
        self.RestoreElastic(path_to_container)
        self.RestoreCassandra(path_to_container)
        self.RestoreDirsAndFiles(path_to_container)


class ContentservCS:
    """A Contentserv-CS instance"""
    def __init__(self, webroot, url, backup_dir, restore_dir):
        if not os.path.isdir(webroot):
            printerr("specified webroot dir does not exist")
            raise SystemExit(1)
        self.webroot = webroot
        self.url = url

        # Find all occurences of config.php file and filter only those, which
        # are 'project anchors'
        filenames_and_wildcards = ['config.php']
        filematches = []

        for root, dirnames, filenames in os.walk(self.webroot):
            for extensions in filenames_and_wildcards:
                for filename in fnmatch.filter(filenames, extensions):
                    filematches.append(os.path.join(root, filename))

        filematches_relative = [x[len(self.webroot):] for x in filematches]

        self.projects = []
        self.projects = [ContentservProject(x, self.webroot) for x in filematches_relative
                         if re.search(cs_project_config_regex, x)]

        self.dirs_to_backup = ['admin.local/lib/activemq/linux/data/kahadb']
        self.ee_startstop_script = 'sudo ' + os.path.join(self.webroot, cs_ee_startstop_script)

        self.backup_dir = backup_dir
        self.restore_dir = restore_dir

    def TarCore(self, path_to_container):
        files_dump = os.path.join(path_to_container, 'core_files.tar.xz')
        dirs_list = ''
        for dname in self.dirs_to_backup:
            dirs_list = dirs_list + ' ' + dname
        tar_call = 'tar cJf ' + files_dump + ' -C ' + self.webroot + ' ' + dirs_list
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("Cannot backup core files...")
            if os.path.exists(files_dump):
                printdeb("Deleting the empty archive")
                os.unlink(files_dump)
            return
        printdeb("Core files and dirs archived successfully")

    def RestoreCore(self):
        files_dump = os.path.join(self.restore_dir, 'core_files.tar.xz')
        tar_call = 'sudo tar xJf ' + files_dump + ' -C ' + self.webroot
        printdeb("tar will be called:", tar_call)
        tar_retval = subprocess.call(tar_call, shell=True)
        if tar_retval != 0:
            printerr("Cannot restore core files...")
            return
        printdeb("Core files and dirs restored successfully")

    def DoPauseDaemons(self):
        printinf("Pause ActiveJobs in CS...")
        response = requests.get(self.url + '/admin/rest/activescript/pauserunningactivescriptjobs')
        if not response.ok:
            printerr("Unable to pause ActiveJobs, aborting...")
            raise SystemExit(1)
        cs_response = response.json()
        if cs_response['success']:
            printinf("OK, ActiveJobs paused")
        else:
            printerr("Unable to pause ActiveJobs, aborting...")
            raise SystemExit(1)

        printinf("Suspending ExportExecutor(s) and ActiveMQ")
        printdeb("Suspending ExportExecutor(s) and ActiveMQ using the script:", self.ee_startstop_script)
        # Here comes the call of external bash script
        ee_startstop_retval = subprocess.call(self.ee_startstop_script + ' pause', shell=True)
        printdeb("Script returned:", ee_startstop_retval)

        printdeb("Stop Apache to minimize possible inconsistencies")
        ApacheStop()

    def DoResumeDaemons(self):
        printdeb("Start Apache")
        ApacheStart()

        printinf("Resume ExportExecutor(s) and ActiveMQ...")
        ee_startstop_retval = subprocess.call(self.ee_startstop_script + ' resume', shell=True)
        printdeb("Script returned:", ee_startstop_retval)

        printinf("Resuming CS ActiveJobs...")
        # Here comes corresponding REST call
        response = requests.get(self.url + '/admin/rest/activescript/restartpausedactivescriptjobs')
        if not response.ok:
            printerr("Unable to resume ActiveJobs, aborting...")
            raise SystemExit(1)
        cs_response = response.json()
        if cs_response['success']:
            printinf("OK, ActiveJobs resumed")
        else:
            printerr("Unable to resume ActiveJobs, aborting...")
            raise SystemExit(1)

    def DoBackup(self):
        printdeb("DoBackup() method")

        printdeb("Creating container sub directory")
        backup_container = CreateNowDir(self.backup_dir)
        printinf("Backup container created:", backup_container)
        self.DoPauseDaemons()

        for project in self.projects:
            project.DoBackup(backup_container)

        printinf("Backup core data")
        # Here comes backup of core files/dirs
        self.TarCore(backup_container)

        # The backup is done, create/update the symlink
        CreateLatestLink(backup_container)
        self.DoResumeDaemons()

    def DoRestore(self):
        printdeb("DoRestore() method placeholder")
        # First, check if the restore directory exists and contains files needed to perform restore
        if os.path.isdir(self.restore_dir):
            printdeb("Restore dir exists, proceed...")
        else:
            printerr("Restore dir does not exists (or it's not a directory)")
            raise SystemExit(1)

        self.DoPauseDaemons()
        # Here comes restore functionality
        for project in self.projects:
            project.DoRestore(self.restore_dir)
        self.RestoreCore()

        self.DoResumeDaemons()



try:
    env_contentserv_root = os.environ["CONTENTSERV_ROOT"]
    printdeb("Global variable CONTENTSERV_ROOT is set, can be overwritten with command-line option")
except:
    printdeb("Global variable CONTENTSERV_ROOT is undetermined, assuming default or command")

called_as = os.path.basename(os.path.normpath(sys.argv[0]))
printdeb("We are called as:", called_as)
if called_as == 'cs-restore':
    cs_restore_mode = True

try:
    env_user = os.environ["USER"]
except:
    printerr("Unable to detect user name from the environment, wrong platform?..")
    raise SystemExit(1)

try:
    pycharm_detected = (os.environ["RUN_IN_PYCHARM"] == 'true')
except:
    printdeb("Started not under PyCharm, root is mandatory")
    pycharm_detected = False

if pycharm_detected:
    printdeb("Started under PyCharm, root is not necessary")
else:
    if env_user != 'root':
        printerr("This script should be started as root")
        raise SystemExit(1)
    else:
        printdeb("OK, started as root")

arg_parser = argparse.ArgumentParser()
arg_parser.add_argument("-r", "--contentserv-root", nargs=1, default=".",
                        help="set the path to contentserv webroot directory, assumes current if omitted and if "
                             "no global variable CONTENTSERV_ROOT is set. If both global variable and command "
                             "line option are set, the latter takes precedence")
arg_parser.add_argument("-b", "--backup-dir", nargs=1, default="backup",
                        help="set the path to contentserv backup directory, assumes \'backup\' if omitted, "
                             "works with both relative and absolute paths, relative will be placed under "
                             "$CONTENTSERV_ROOT. In restore mode it\'s where the script searches for the archived data")
arg_parser.add_argument("-u", "--contentserv-url", nargs=1, default="http://localhost/contentserv",
                        help="set the URL to contentserv installation, assumes \'http://localhost/contentserv\'  if "
                             "omitted, be aware of proper name resolution (/etc/hosts or DNS) if the hostname differs "
                             "from \'localhost\' and don\'t forget to take care about proper certificates "
                             "if SSL/TLS is enabled or enforced")
arg_parser.add_argument("-S", "--restore-dirname", nargs=1, default="latest",
                        help="restore command, accepts optional name of the directory with the backup content "
                             "if not specified, the name \'latest\' will be used, which normally is a symlink to "
                             "the last successful backup ")
arg_parser.add_argument("-R", "--restore", action="store_true")

args = arg_parser.parse_args()

# If passed as a command-line argument, string becomes list object ('list of strings' with single element),
# convert them safely and forcefully back to strings, join() is the safe method, allowing both lists and strings
contentserv_root_str = ''.join(args.contentserv_root)
backup_dir_str = ''.join(args.backup_dir)
contentserv_url = ''.join(args.contentserv_url)
restore_dir_str = ''.join(args.restore_dirname)
cs_root_path = os.path.abspath(contentserv_root_str)
# CS Backup path can be relative to Webroot or absolute, if starts with '/'
cs_backup_path = backup_dir_str if backup_dir_str.startswith('/') else os.path.join(cs_root_path,
                                                                                    backup_dir_str)
# Restore mode is switched on either by the program name (called as cs-restore, the symlink)
# or with the optional argument "-R"
cs_restore_mode = cs_restore_mode | args.restore
# CS Restore path can be relative to backup path or absolute, if starts with '/'
cs_restore_path = restore_dir_str if restore_dir_str.startswith('/') else os.path.join(cs_backup_path,
                                                                                       restore_dir_str)
printdeb("CS Webroot normalized path:", cs_root_path)
printdeb("CS Backup full path:", cs_backup_path)
printdeb("CS Restore full path:", cs_restore_path)

cs_instance = ContentservCS(cs_root_path, contentserv_url, cs_backup_path, cs_restore_path)
if cs_restore_mode:
    cs_instance.DoRestore()
else:
    cs_instance.DoBackup()
